# WASM vs Python ML Benchmark

Questo setup permette di confrontare le performance di un'applicazione ML tra:
- **Python nativo** con RAPIDS (GPU accelerato via CUDA)
- **WebAssembly** con wgpu (GPU accelerato via WebGPU)

## ğŸ“‹ Configurazione Identica

Entrambe le implementazioni usano:
- **Dataset**: sklearn diabetes (442 samples, 10 features)
- **Split**: 80/20 train/test con `random_state=42`
- **Modello**: RandomForest Regressor
  - `n_estimators`: 200
  - `max_depth`: 16
  - Task: Regressione (MSE)

## ğŸš€ Esecuzione

### Opzione 1: Benchmark Singoli

**Python (RAPIDS):**
```powershell
.\run_python_benchmark.ps1
```

**WASM:**
```powershell
.\run_wasm_benchmark.ps1
```

### Opzione 2: Confronto Completo

Esegui entrambi in sequenza per confrontare i risultati:

```powershell
# Python
.\run_python_benchmark.ps1

# WASM
.\run_wasm_benchmark.ps1
```

## ğŸ“Š Output Atteso

### Python (RAPIDS)
```
[TRAINING] Avvio training su GPU (cuML RandomForest)...
[TRAINING] Completato.
[TRAINING] Modello e test set salvati in model_diabetes_gpu.pkl
[INFERENZA] Predizione su test set (GPU)...
[INFERENZA] Campioni: 89
[INFERENZA] Mean Squared Error (GPU): XXXX.XXXX
```

### WASM
```
=== TRAINING PHASE ===
[TRAINING] Creating RandomForest with 200 estimators, max_depth 16
[TRAINING] Starting training on CPU...
[TRAINING] Training completed!
[TRAINING] Model saved to: data/model_diabetes_wasm.bin

=== INFERENCE PHASE ===
[INFERENCE] Running predictions on 89 test samples...
[INFERENCE] Samples: 89
[INFERENCE] Mean Squared Error (CPU): XXXX.XXXX
```

## ğŸ“ File Generati

### Python
- `model_diabetes_gpu.pkl` - Modello cuML serializzato

### WASM
- `wasm-ml/data/diabetes_train.csv` - Dataset training
- `wasm-ml/data/diabetes_test.csv` - Dataset test
- `wasm-ml/data/model_diabetes_wasm.bin` - Modello Rust serializzato
- `wasm-ml/target/release/wasm-ml-benchmark.exe` - Binario compilato

## ğŸ”„ Workflow Completo

### Python
```
main.py
  â†“
train_model.py â†’ MLTrainer.train_and_split()
  â†“
  â€¢ Carica diabetes
  â€¢ Split 80/20
  â€¢ Training cuML RandomForest (GPU)
  â€¢ Salva model_diabetes_gpu.pkl
  â†“
infer_model.py â†’ MLInferencer.run_inference()
  â†“
  â€¢ Carica model_diabetes_gpu.pkl
  â€¢ Inferenza su test set (GPU)
  â€¢ Calcola e stampa MSE
```

### WASM
```
run_wasm_benchmark.ps1
  â†“
export_diabetes_for_wasm.py
  â†“
  â€¢ Carica diabetes
  â€¢ Split 80/20 (stesso random_state=42)
  â€¢ Esporta CSV
  â†“
cargo build --release
  â†“
wasm-ml-benchmark.exe
  â†“
train_and_save()
  â†“
  â€¢ Carica diabetes_train.csv
  â€¢ Training RandomForest (CPU)
  â€¢ Salva model_diabetes_wasm.bin
  â†“
load_and_infer()
  â†“
  â€¢ Carica diabetes_test.csv
  â€¢ Carica model_diabetes_wasm.bin
  â€¢ Inferenza su test set (CPU)
  â€¢ Calcola e stampa MSE
```

## âš™ï¸ Requisiti

### Python
- Python 3.x
- cuML (RAPIDS)
- cuDF
- cuPy
- scikit-learn
- joblib
- NVIDIA GPU con CUDA

### WASM
- Rust toolchain (rustc, cargo)
- Target: native (non wasm32 per ora, binario Windows)
- No GPU richiesta per questa versione (CPU-only training)

## ğŸ” Verifica Dati Identici

Per verificare che i dataset siano identici:

```powershell
# Conta righe
(Get-Content wasm-ml\data\diabetes_train.csv).Count  # Deve essere 354 (353 + header)
(Get-Content wasm-ml\data\diabetes_test.csv).Count   # Deve essere 90 (89 + header)
```

## âš ï¸ Note Importanti

1. **Random State**: Entrambi usano `random_state=42` per garantire split identico
2. **Test Set**: Il test set Ã¨ ESATTAMENTE lo stesso (esportato da Python)
3. **GPU vs CPU**: 
   - Python: Training e Inferenza su GPU (CUDA/cuML)
   - WASM: Training su CPU, Inferenza CPU (futura GPU via WebGPU)
4. **MSE**: Potrebbero esserci piccole differenze dovute a:
   - Implementazione algoritmo (cuML vs Rust custom)
   - Precisione numerica (float32 vs float64)
   - Ordine operazioni (GPU parallelismo)

## ğŸ“ˆ Cosa Confrontare

- âœ… **MSE**: Dovrebbe essere simile (Â±5-10%)
- âœ… **Tempo Training**: Python GPU vs Rust CPU
- âœ… **Tempo Inferenza**: Python GPU vs Rust CPU
- â³ **Memoria**: (non misurato in questa versione)

## ğŸš§ Limitazioni Attuali

### WASM Implementation
- âŒ GPU training non implementato
- âŒ GPU inference non implementato
- âœ… Stessi parametri modello
- âœ… Stesso dataset e split
- âœ… Stessa sequenza operazioni

### Prossimi Step
1. Implementare GPU inference via WebGPU
2. Implementare GPU training (se fattibile)
3. Aggiungere timing preciso
4. Deploy su Azure H100

## ğŸ“ Debugging

Se l'MSE Ã¨ molto diverso:
1. Verifica che i CSV siano stati generati correttamente
2. Controlla il numero di sample in train/test
3. Verifica che random_state sia 42 in entrambi
4. Controlla i parametri RandomForest (200 trees, depth 16)
